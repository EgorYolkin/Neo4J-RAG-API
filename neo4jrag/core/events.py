"""
Application lifecycle events (startup/shutdown)
"""
import logging
from typing import Optional

from neo4jrag.services.cache.semantic_cache import SemanticCache

from neo4jrag.config import Config
from neo4jrag.services.neo4j.neo4j_connector import Neo4jConnector
from neo4jrag.services.neo4j.graph_builder import GraphBuilder
from neo4jrag.services.neo4j.vector_store import VectorStore
from neo4jrag.services.ollama.ollama_loader import OllamaLoader
from neo4jrag.services.ollama.rag_pipeline import RAGPipeline
from neo4jrag.services.entity_extractor.hybrid_entity_extractor import HybridEntityExtractor
from .exceptions import RAGInitializationError

logger = logging.getLogger(__name__)


async def startup_event(config: Config) -> dict:
    """
    Startup event handler
    
    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã:
    1. –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Neo4j
    2. –ó–∞–≥—Ä—É–∑–∫–∞ Ollama –º–æ–¥–µ–ª–µ–π
    3. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ö–µ–º—ã –≥—Ä–∞—Ñ–∞
    4. –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
    5. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG pipeline
    
    Returns:
        dict: –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
    """
    logger.info("=" * 80)
    logger.info("üöÄ Starting Neo4j RAG System")
    logger.info("=" * 80)
    
    components = {}
    
    try:
        # 1. Neo4j Connection
        logger.info("üìä Connecting to Neo4j...")
        neo4j_connector = Neo4jConnector(
            uri=config.neo4j.uri,
            username=config.neo4j.username,
            password=config.neo4j.password,
            database=config.neo4j.database
        )
        neo4j_connector.connect()
        components["neo4j_connector"] = neo4j_connector
        logger.info(f"‚úì Connected to Neo4j at {config.neo4j.uri}")
        
        # 2. Ollama Models
        logger.info("ü§ñ Loading Ollama models...")
        ollama_loader = OllamaLoader(
            base_url=config.ollama.base_url,
            model=config.ollama.model,
            embedding_model=config.ollama.embedding_model,
            temperature=config.ollama.temperature
        )
        ollama_loader.load_llm()
        ollama_loader.load_embeddings()
        components["ollama_loader"] = ollama_loader
        logger.info(f"‚úì Loaded LLM: {config.ollama.model}")
        logger.info(f"‚úì Loaded Embeddings: {config.ollama.embedding_model}")
        
        # 3. Graph Builder
        logger.info("üìö Setting up Graph Builder...")
        graph_builder = GraphBuilder(
            connector=neo4j_connector,
            chunk_size=config.rag.chunk_size,
            chunk_overlap=config.rag.chunk_overlap
        )
        graph_builder.setup_schema()
        components["graph_builder"] = graph_builder
        logger.info("‚úì Graph schema configured")
        
        # 4. Vector Store
        logger.info("üîç Setting up Vector Store...")
        vector_store = VectorStore(
            connector=neo4j_connector,
            ollama=ollama_loader,
            index_name=config.rag.vector_index_name,
            dimensions=config.rag.embedding_dimension
        )
        vector_store.create_vector_index()
        components["vector_store"] = vector_store
        logger.info(f"‚úì Vector index '{config.rag.vector_index_name}' ready")
        
        # 5. RAG Pipeline
        logger.info("‚öôÔ∏è Initializing RAG Pipeline...")
        rag_pipeline = RAGPipeline(
            vector_store=vector_store,
            ollama=ollama_loader
        )
        components["rag_pipeline"] = rag_pipeline
        logger.info("‚úì RAG Pipeline initialized")

        logger.info("üíæ Connecting to Redis...")
        semantic_cache = SemanticCache(
            host=config.redis.host,
            port=config.redis.port,
            password=config.redis.password,
            db=config.redis.db,
            ttl=config.redis.cache_ttl,
            similarity_threshold=config.redis.semantic_cache_threshold,
            max_cache_size=config.redis.max_cache_size
        )
        components["semantic_cache"] = semantic_cache
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—ç—à–∞
        cache_stats = semantic_cache.get_stats()
        logger.info(f"‚úì Redis connected (cache size: {cache_stats.get('cache_size', 0)})")

        # 6. Hybrid Entity Extractor
        logger.info("üß© Initializing Hybrid Entity Extractor...")
        hybrid_extractor = HybridEntityExtractor(
            neo4j_connector=neo4j_connector,
            language="ru"  # –∏–ª–∏ "en"
        )
        components["entity_extractor"] = hybrid_extractor
        logger.info("‚úì Hybrid Entity Extractor initialized")

        
        # 6. Initial Statistics
        logger.info("\nüìä System Statistics:")
        try:
            stats = neo4j_connector.get_statistics()
            for node_type, count in stats.get("nodes", {}).items():
                logger.info(f"  ‚Ä¢ {node_type}: {count} nodes")
            for rel_type, count in stats.get("relationships", {}).items():
                logger.info(f"  ‚Ä¢ {rel_type}: {count} relationships")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            embeddings_query = """
            MATCH (c:Chunk)
            RETURN 
                count(c) as total,
                count(c.embedding) as with_embeddings
            """
            emb_result = neo4j_connector.execute_query(embeddings_query)
            if emb_result:
                total = emb_result[0]["total"]
                with_emb = emb_result[0]["with_embeddings"]
                coverage = (with_emb / total * 100) if total > 0 else 0
                logger.info(f"  ‚Ä¢ Embeddings coverage: {with_emb}/{total} ({coverage:.1f}%)")
        except Exception as e:
            logger.warning(f"Could not fetch statistics: {e}")
        
        logger.info("\n" + "=" * 80)
        logger.info("‚úÖ System startup completed successfully")
        logger.info("=" * 80 + "\n")
        
        return components
        
    except Exception as e:
        logger.error("=" * 80)
        logger.error(f"‚ùå Startup failed: {str(e)}")
        logger.error("=" * 80)
        
        # Cleanup —á–∞—Å—Ç–∏—á–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        await cleanup_components(components)
        
        raise RAGInitializationError(f"System startup failed: {str(e)}")


async def shutdown_event(components: dict) -> None:
    """
    Shutdown event handler
    
    –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∑–∞–∫—Ä—ã–≤–∞–µ—Ç –≤—Å–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –∏ –æ—Å–≤–æ–±–æ–∂–¥–∞–µ—Ç —Ä–µ—Å—É—Ä—Å—ã:
    1. –ó–∞–∫—Ä—ã–≤–∞–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Neo4j
    2. –û—á–∏—â–∞–µ—Ç –∫—ç—à–∏
    3. –õ–æ–≥–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    
    Args:
        components: –°–ª–æ–≤–∞—Ä—å —Å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏ —Å–∏—Å—Ç–µ–º—ã
    """
    logger.info("\n" + "=" * 80)
    logger.info("üõë Shutting down Neo4j RAG System")
    logger.info("=" * 80)
    
    await cleanup_components(components)
    
    logger.info("=" * 80)
    logger.info("üëã System shutdown completed")
    logger.info("=" * 80 + "\n")


async def cleanup_components(components: dict) -> None:
    """
    –û—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã
    
    Args:
        components: –°–ª–æ–≤–∞—Ä—å —Å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
    """
    # –ó–∞–∫—Ä—ã–≤–∞–µ–º Neo4j —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
    neo4j_connector = components.get("neo4j_connector")
    if neo4j_connector:
        try:
            # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã—Ç–∏–µ–º
            logger.info("\nüìä Final Statistics:")
            stats = neo4j_connector.get_statistics()
            for node_type, count in stats.get("nodes", {}).items():
                logger.info(f"  ‚Ä¢ {node_type}: {count} nodes")
            for rel_type, count in stats.get("relationships", {}).items():
                logger.info(f"  ‚Ä¢ {rel_type}: {count} relationships")
            
            neo4j_connector.close()
            logger.info("‚úì Neo4j connection closed")
        except Exception as e:
            logger.error(f"Error closing Neo4j connection: {e}")

    semantic_cache = components.get("semantic_cache")
    if semantic_cache:
        try:
            cache_stats = semantic_cache.get_stats()
            logger.info(f"\nüíæ Final Cache Statistics:")
            logger.info(f"  ‚Ä¢ Total requests: {cache_stats.get('total_requests', 0)}")
            logger.info(f"  ‚Ä¢ Cache hits: {cache_stats.get('total_hits', 0)}")
            logger.info(f"  ‚Ä¢ Cache misses: {cache_stats.get('total_misses', 0)}")
            logger.info(f"  ‚Ä¢ Hit rate: {cache_stats.get('hit_rate', 0)}%")
            
            semantic_cache.close()
            logger.info("‚úì Redis connection closed")
        except Exception as e:
            logger.error(f"Error closing Redis connection: {e}")
    
    # –û—á–∏—â–∞–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
    components_to_clear = ["rag_pipeline", "vector_store", "graph_builder", "ollama_loader"]
    for comp_name in components_to_clear:
        if comp_name in components:
            components[comp_name] = None
            logger.info(f"‚úì Cleared {comp_name}")
    
    components.clear()


async def health_check_event(components: dict) -> dict:
    """
    –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    
    Args:
        components: –°–ª–æ–≤–∞—Ä—å —Å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏ —Å–∏—Å—Ç–µ–º—ã
    
    Returns:
        dict: –°—Ç–∞—Ç—É—Å –∫–∞–∂–¥–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
    """
    health_status = {
        "overall": "healthy",
        "components": {}
    }
    
    # Neo4j
    try:
        neo4j_connector = components.get("neo4j_connector")
        if neo4j_connector:
            # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            neo4j_connector.execute_query("RETURN 1")
            health_status["components"]["neo4j"] = "healthy"
        else:
            health_status["components"]["neo4j"] = "not_initialized"
            health_status["overall"] = "degraded"
    except Exception as e:
        health_status["components"]["neo4j"] = f"unhealthy: {str(e)}"
        health_status["overall"] = "unhealthy"
    
    # Ollama
    try:
        ollama_loader = components.get("ollama_loader")
        if ollama_loader:
            # –¢–µ—Å—Ç–æ–≤—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥
            test_embedding = ollama_loader.embed_text("health check")
            if len(test_embedding) > 0:
                health_status["components"]["ollama"] = "healthy"
            else:
                health_status["components"]["ollama"] = "unhealthy: empty embedding"
                health_status["overall"] = "unhealthy"
        else:
            health_status["components"]["ollama"] = "not_initialized"
            health_status["overall"] = "degraded"
    except Exception as e:
        health_status["components"]["ollama"] = f"unhealthy: {str(e)}"
        health_status["overall"] = "unhealthy"
    
    # RAG Pipeline
    rag_pipeline = components.get("rag_pipeline")
    if rag_pipeline:
        health_status["components"]["rag_pipeline"] = "healthy"
    else:
        health_status["components"]["rag_pipeline"] = "not_initialized"
        health_status["overall"] = "degraded"
    
    return health_status


async def warm_up_event(components: dict) -> None:
    """
    –ü—Ä–æ–≥—Ä–µ–≤ —Å–∏—Å—Ç–µ–º—ã –ø–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞
    
    –í—ã–ø–æ–ª–Ω—è–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è:
    - –ü—Ä–æ–≥—Ä–µ–≤–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
    - –ó–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π –≤ –ø–∞–º—è—Ç—å
    - –ü—Ä–æ–≤–µ—Ä–∫–∏ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏
    
    Args:
        components: –°–ª–æ–≤–∞—Ä—å —Å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏ —Å–∏—Å—Ç–µ–º—ã
    """
    logger.info("üî• Warming up system...")
    
    try:
        # –ü—Ä–æ–≥—Ä–µ–≤ Ollama
        ollama_loader = components.get("ollama_loader")
        if ollama_loader:
            logger.info("  ‚Ä¢ Warming up Ollama models...")
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥
            test_embedding = ollama_loader.embed_text("test warmup query")
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç
            test_response = ollama_loader.generate("Say 'ready' if you are working.")
            logger.info("  ‚úì Ollama models warmed up")
        
        # –ü—Ä–æ–≥—Ä–µ–≤ Neo4j
        neo4j_connector = components.get("neo4j_connector")
        if neo4j_connector:
            logger.info("  ‚Ä¢ Warming up Neo4j connection...")
            # –ù–µ—Å–∫–æ–ª—å–∫–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            neo4j_connector.execute_query("RETURN 1")
            neo4j_connector.execute_query("MATCH (n) RETURN count(n) LIMIT 1")
            logger.info("  ‚úì Neo4j connection warmed up")
        
        # –ü—Ä–æ–≥—Ä–µ–≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
        vector_store = components.get("vector_store")
        if vector_store:
            logger.info("  ‚Ä¢ Warming up vector search...")
            try:
                # –¢–µ—Å—Ç–æ–≤—ã–π –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫
                vector_store.similarity_search("test query", k=1)
                logger.info("  ‚úì Vector search warmed up")
            except Exception as e:
                logger.warning(f"  ‚ö† Vector search warmup failed: {e}")
        
        logger.info("‚úì System warmup completed\n")
        
    except Exception as e:
        logger.warning(f"Warmup encountered issues: {e}")


async def initialize_sample_data(components: dict) -> None:
    """
    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö (–¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏)
    
    Args:
        components: –°–ª–æ–≤–∞—Ä—å —Å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏ —Å–∏—Å—Ç–µ–º—ã
    """
    logger.info("üìù Checking for sample data...")
    
    neo4j_connector = components.get("neo4j_connector")
    graph_builder = components.get("graph_builder")
    vector_store = components.get("vector_store")
    
    if not all([neo4j_connector, graph_builder, vector_store]):
        logger.warning("Components not ready for sample data initialization")
        return
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        count_query = "MATCH (d:Document) RETURN count(d) as count"
        result = neo4j_connector.execute_query(count_query)
        doc_count = result[0]["count"] if result else 0
        
        if doc_count > 0:
            logger.info(f"‚úì Found {doc_count} existing documents, skipping sample data")
            return
        
        logger.info("Adding sample documents...")
        
        sample_docs = [
            {
                "id": "sample_ml",
                "title": "–í–≤–µ–¥–µ–Ω–∏–µ –≤ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ",
                "content": """
                –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ (Machine Learning, ML) ‚Äî —ç—Ç–æ —Ä–∞–∑–¥–µ–ª –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞, 
                –∫–æ—Ç–æ—Ä—ã–π –∏–∑—É—á–∞–µ—Ç –º–µ—Ç–æ–¥—ã –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤, —Å–ø–æ—Å–æ–±–Ω—ã—Ö –æ–±—É—á–∞—Ç—å—Å—è –Ω–∞ –¥–∞–Ω–Ω—ã—Ö.
                
                –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–∏–ø—ã –æ–±—É—á–µ–Ω–∏—è –≤–∫–ª—é—á–∞—é—Ç:
                1. –û–±—É—á–µ–Ω–∏–µ —Å —É—á–∏—Ç–µ–ª–µ–º (Supervised Learning) - –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                2. –û–±—É—á–µ–Ω–∏–µ –±–µ–∑ —É—á–∏—Ç–µ–ª—è (Unsupervised Learning) - –ø–æ–∏—Å–∫ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ –Ω–µ—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                3. –û–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º (Reinforcement Learning) - –æ–±—É—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å–æ —Å—Ä–µ–¥–æ–π
                
                –ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ —è–≤–ª—è—é—Ç—Å—è –∫–ª—é—á–µ–≤—ã–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–º –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. –û–Ω–∏ —Å–æ—Å—Ç–æ—è—Ç 
                –∏–∑ —Å–ª–æ—ë–≤ –Ω–µ–π—Ä–æ–Ω–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –≤—ã—è–≤–ª—è—é—Ç —Å–ª–æ–∂–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã.
                """,
                "metadata": {"category": "AI", "difficulty": "beginner"}
            },
            {
                "id": "sample_graphdb",
                "title": "–ì—Ä–∞—Ñ–æ–≤—ã–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏ Neo4j",
                "content": """
                –ì—Ä–∞—Ñ–æ–≤—ã–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö, —Ç–∞–∫–∏–µ –∫–∞–∫ Neo4j, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ 
                —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –û–Ω–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç —É–∑–ª—ã –¥–ª—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å—É—â–Ω–æ—Å—Ç–µ–π –∏ —Ä—ë–±—Ä–∞ –¥–ª—è 
                —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –Ω–∏–º–∏.
                
                –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –≥—Ä–∞—Ñ–æ–≤—ã—Ö –ë–î:
                - –ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–≤—è–∑–µ–π
                - –í—ã—Å–æ–∫–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø—Ä–∏ –æ–±—Ö–æ–¥–µ –≥—Ä–∞—Ñ–∞
                - –ì–∏–±–∫–∞—è —Å—Ö–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö
                - –ú–æ—â–Ω—ã–π —è–∑—ã–∫ –∑–∞–ø—Ä–æ—Å–æ–≤ Cypher
                
                RAG (Retrieval-Augmented Generation) ‚Äî —ç—Ç–æ –ø–æ–¥—Ö–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –∫–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç –ø–æ–∏—Å–∫ 
                —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –æ—Ç–≤–µ—Ç–æ–≤ —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª—å—é. GraphRAG —Ä–∞—Å—à–∏—Ä—è–µ—Ç 
                —ç—Ç–æ—Ç –ø–æ–¥—Ö–æ–¥, –∏—Å–ø–æ–ª—å–∑—É—è –≥—Ä–∞—Ñ–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
                """,
                "metadata": {"category": "Databases", "difficulty": "intermediate"}
            }
        ]
        
        for doc in sample_docs:
            graph_builder.add_document(
                doc_id=doc["id"],
                title=doc["title"],
                content=doc["content"],
                metadata=doc["metadata"]
            )
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        vector_store.generate_embeddings()
        
        logger.info(f"‚úì Added {len(sample_docs)} sample documents\n")
        
    except Exception as e:
        logger.warning(f"Failed to initialize sample data: {e}")
